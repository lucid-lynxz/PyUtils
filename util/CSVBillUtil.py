import os
import re
from typing import List, Optional, Dict, Tuple

import pandas as pd
import numpy as np
from util.CSVUtil import CSVUtil
from util.CommonUtil import CommonUtil
from util.FileUtil import FileUtil

"""
ä¾èµ–åº“: pip install pdfplumber matplotlib pillow numpy

åˆå¹¶å½“å‰ç›®å½•ä¸‹é™¤ output_name ä»¥åŠ 'ignore_' å¼€å¤´çš„æ‰€æœ‰ csv æ–‡ä»¶, å¹¶å»é‡, ä¿å­˜ä¸º output_name
è¦è¯»å–å’Œä¿å­˜çš„åˆ—åä¸ºç”± usecols å®šä¹‰, è¯·ç¡®ä¿è¿™äº›åˆ—åå­˜åœ¨
æœ€åä¼šæ–°å¢ä¸€åˆ—: result_src ç”¨ä»¥è®°å½•å½“å‰æ•°æ®æ¥æºäºå“ªä»½æ–‡æ¡£
å…¶ä»–å˜é‡å«ä¹‰è¯´æ˜: 
 skip_rows: æŒ‡å®šè¦è·³è¿‡çš„è¡¨å¤´è¡Œæ•°
 deduplicate_on_column: å»é‡æ•°æ®æ—¶çš„åˆ—ä¾æ® 
 output_dir: è¦åˆå¹¶çš„csvæ–‡ä»¶æ‰€åœ¨çš„ç›®å½•, é»˜è®¤æ˜¯å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
 output_csv_name: æœ€ç»ˆåˆå¹¶ç”Ÿæˆçš„csvæ–‡ä»¶å(ä¸åŒ…å« .csv åç¼€)

å¯¹äºå¾®ä¿¡å¯¹è´¦å•excelæ–‡ä»¶, ä¼šå…ˆè½¬åŒ–ä¸ºcsv, ç„¶ååˆå¹¶csv(åŸºäºæ—¶é—´å»é‡)
å¾®ä¿¡å¯¹è´¦å•å‰16è¡Œä¸ºç»Ÿè®¡ä¿¡æ¯è¡¨å¤´, éœ€è¦è·³è¿‡
å¾®ä¿¡å¯¹è´¦å•çš„è¯¦æƒ…åˆ—åä¸º("å¾®ä¿¡ - æˆ‘ - æœåŠ¡ - é’±åŒ… - è´¦å• - å³ä¸Šè§’... - ä¸‹è½½è´¦å• - ç”¨äºä¸ªäººå¯¹è´¦"):
äº¤æ˜“æ—¶é—´,äº¤æ˜“ç±»å‹,äº¤æ˜“å¯¹æ–¹,å•†å“,æ”¶/æ”¯,é‡‘é¢(å…ƒ),æ”¯ä»˜æ–¹å¼,å½“å‰çŠ¶æ€,äº¤æ˜“å•å·,å•†æˆ·å•å·,å¤‡æ³¨
å¾®ä¿¡å•æ¬¡ç”³è¯·çš„æ—¶é•¿è·¨åº¦æ˜¯3ä¸ªæœˆ, æ¯æ¬¡éƒ½éœ€è¦è¿›è¡Œäººè„¸éªŒè¯, è‹¥ä¸‹é¢åˆ™å‘é€åˆ°é‚®ç®±, æ¯æ¬¡éƒ½è¦è¾“é‚®ç®±, æœ€ç»ˆé‚®ä»¶é™„ä»¶å‹ç¼©åŒ…ä¼šå¸¦æœ‰å¯†ç 

æ”¯ä»˜å®è´¦å•åˆ—å(â€œæ”¯ä»˜å® - æˆ‘çš„ - è´¦å• - å³ä¸Šè§’... - å¼€å…·äº¤æ˜“æµæ°´è¯æ˜"):
äº¤æ˜“æ—¶é—´,äº¤æ˜“åˆ†ç±»,äº¤æ˜“å¯¹æ–¹,å¯¹æ–¹è´¦å·,å•†å“è¯´æ˜,æ”¶/æ”¯,é‡‘é¢,    æ”¶/ä»˜æ¬¾æ–¹å¼,äº¤æ˜“çŠ¶æ€,äº¤æ˜“è®¢å•å·,å•†å®¶è®¢å•å·,å¤‡æ³¨,
æ”¯ä»˜å®å•æ¬¡ç”³è¯·çš„æ—¶é•¿è·¨åº¦æ˜¯1å¹´

æ‹›å•†é“¶è¡Œåˆ—å("é¦–é¡µ - æ”¶æ”¯æ˜ç»† -å³ä¸Šè§’... - æ‰“å°æµæ°´"):
è®°è´¦æ—¥æœŸ,è´§å¸,äº¤æ˜“é‡‘é¢,è”æœºä½™é¢,äº¤æ˜“æ‘˜è¦,å¯¹æ‰‹ä¿¡æ¯
æ‹›å•†é“¶è¡Œå•æ¬¡ç”³è¯·çš„æ—¶é•¿è·¨åº¦æœ€å¤§æ˜¯10å¹´, å•æ¬¡æœ€å¤§å¯¼å‡ºè®°å½•æ˜¯2wæ¡, ä½†åªæ”¯æŒåˆ°å¤„pdfæ–‡ä»¶,å› æ­¤æœ¬è„šæœ¬æœªå¯¹å…¶è¿›è¡Œé€‚é…

ä½¿ç”¨æ–¹æ³•:
1. è¿è¡Œæœ¬è„šæœ¬, æ ¹æ®æç¤ºè¾“å…¥: å¾®ä¿¡&æ”¯ä»˜å®å¯¼å‡ºçš„å¯¹è´¦å•excelæ–‡ä»¶æ‰€åœ¨ç›®å½•åœ°å€ ä»¥åŠæ˜¯å¦è¦é‡æ–°åˆå¹¶(é»˜è®¤ç›´æ¥å›è½¦å³å¯)
2. æ ¹æ®æç¤ºè¾“å…¥è¦ç‰¹åˆ«è¿›è¡Œç»Ÿè®¡çš„æŒ‡å®šäº¤æ˜“å¯¹è±¡å(æ­£åˆ™è¡¨è¾¾å¼, ä»¥ä¾¿æ¨¡ç³Šæœç´¢å‡ºæ‰€æœ‰åˆ«å)
3. ç»Ÿè®¡ç»“æœä¼šè¾“å‡ºåˆ° {csvç›®å½•}/bill_stats_result.md æ–‡ä»¶ä¸­, ä¸»è¦åŒ…å«ä»¥ä¸‹å†…å®¹:
    3.1 æ•´ä½“æŒ‰æ”¯å‡ºé™åºæ’åˆ—å‰10é¡¹
    3.2 æ•´ä½“æŒ‰å¹´æ”¶æ”¯æƒ…å†µ
    3.3 ç‰¹å®šäº¤æ˜“å¯¹è±¡çš„æ•´ä½“äº¤æ˜“æ±‡æ€»ä»¥åŠæŒ‰å¹´åº¦ç»Ÿè®¡çš„äº¤æ˜“è®°å½•
    
å…¶ä»–è¯´æ˜: è¦ç‰¹åˆ«ç»Ÿè®¡çš„äº¤æ˜“å¯¹è±¡åæ”¯æŒé…ç½®å¤šæ¬¡, æ¯ä¸ªéƒ½ä¼šå•ç‹¬è¿›è¡Œç»Ÿè®¡
"""


class CSVBillUtil(object):
    def __init__(self, csv_dir: str, delete_src_excel: bool = True, ignore_family_card: bool = False):
        """
        :param csv_dir: excel/csvæ–‡ä»¶æ‰€åœ¨ç›®å½•è·¯å¾„, è‹¥ä¸ºç©º, åˆ™è¡¨ç¤ºå½“å‰pyè„šæœ¬æ‰€åœ¨ç›®å½•
        :param delete_src_excel: excelè½¬ä¸ºcsvåæ˜¯å¦è‡ªåŠ¨åˆ é™¤excelæºæ–‡ä»¶
        :param ignore_family_card: æ˜¯å¦å¿½ç•¥äº²å±å¡æ”¯ä»˜æ•°æ®
        """
        # å¾®ä¿¡è´¦å•çš„åˆ—å
        cols_str = 'äº¤æ˜“æ—¶é—´,äº¤æ˜“ç±»å‹,äº¤æ˜“å¯¹æ–¹,å•†å“,æ”¶/æ”¯,é‡‘é¢(å…ƒ),æ”¯ä»˜æ–¹å¼,å½“å‰çŠ¶æ€,äº¤æ˜“å•å·,å•†æˆ·å•å·,å¤‡æ³¨'
        self.usecols = cols_str.split(',')

        if csv_dir is None:
            csv_dir = os.path.dirname(os.path.abspath(__file__))  # å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•

        self.csv_dir = csv_dir
        CSVUtil.convert_dir_excels(csv_dir, delete_src_excel)  # è½¬æ¢ç›®å½•ä¸‹æ‰€æœ‰excelæ–‡ä»¶ä¸ºcsv
        self.ignore_family_card = ignore_family_card
        self.unique_col = 'äº¤æ˜“å•å·'  # å¾®ä¿¡å’Œæ”¯ä»˜å®åˆå¹¶å’Œå»é‡ä¾æ®çš„åˆ—, ç¡®ä¿å”¯ä¸€æ€§, å¦‚: 'äº¤æ˜“æ—¶é—´'  è¯·ä½¿ç”¨äºŒè€…å…±æœ‰çš„å­—æ®µ
        self.df_wx = None  # å¾®ä¿¡è´¦å•åˆå¹¶åçš„æ€»dataframe
        self.df_zfb = None  # æ”¯ä»˜å®è´¦å•åˆå¹¶åçš„æ€»dataframe
        self.df_all = None  # å¾®ä¿¡ & æ”¯ä»˜å® è´¦å•æœ€ç»ˆåˆå¹¶åçš„æ€»dataframe

    def merge_wx_csv(self, output_csv_name: str = 'merge_bill_wx', valid_name_pattern=r'å¾®ä¿¡æ”¯ä»˜') -> pd.DataFrame:
        """
        :param output_csv_name: åˆå¹¶å¾®ä¿¡è´¦å•åç”Ÿæˆçš„csvæ–‡ä»¶å, è‹¥ä¼ ç©º, åˆ™ä¸ä¿å­˜æˆæ–‡ä»¶
        :param valid_name_pattern: è¦åˆå¹¶çš„csvæ–‡ä»¶å(åŒ…å«åç¼€)è¦æ»¡è¶³çš„æ­£åˆ™è¡¨è¾¾å¼
        """
        # åˆå¹¶æ‰€æœ‰å¾®ä¿¡çš„è´¦å•è®°å½•
        _df_wx = CSVUtil.merge_csv_in_dir(self.csv_dir, '', self.unique_col, usecols=self.usecols, skip_rows=16, valid_name_pattern=valid_name_pattern)
        _df_wx['é‡‘é¢(å…ƒ)'] = _df_wx['é‡‘é¢(å…ƒ)'].apply(lambda x: float(str(x).replace('Â¥', '').replace(',', '')))  # å»æ‰ Â¥ ç¬¦å·å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        if self.ignore_family_card:
            _df_wx = _df_wx[~_df_wx['æ”¯ä»˜æ–¹å¼'].str.contains('äº²å±å¡|äº²æƒ…å¡', na=False)]  # na=Falseè¡¨ç¤ºå°†NaNå€¼è§†ä¸ºä¸åŒ…å«
        if not CommonUtil.isNoneOrBlank(output_csv_name):
            CSVUtil.to_csv(_df_wx, f'{self.csv_dir}/{output_csv_name}.csv')

        if self.df_wx is not None:
            self.df_wx = pd.concat([self.df_wx, _df_wx], ignore_index=True)
            CSVUtil.deduplicate(self.df_wx, self.unique_col)
        else:
            self.df_wx = _df_wx
        return _df_wx

    def merge_zfb_csv(self, output_csv_name: str = 'merge_bill_zfb', valid_name_pattern=r'æ”¯ä»˜å®') -> pd.DataFrame:
        """
        åˆå¹¶æ”¯ä»˜å®å¯¹è´¦å•, å¹¶å°†å…¶åˆ—åæ”¹ä¸ºä¸å¾®ä¿¡ä¸€è‡´å, ä¿å­˜ä¸º merge_bill_zfb.csv
        :param output_csv_name: åˆå¹¶å¾®ä¿¡è´¦å•åç”Ÿæˆçš„csvæ–‡ä»¶å(ä¸è¡Œ .csv åç¼€), è‹¥ä¼ ç©º, åˆ™ä¸ä¿å­˜æˆæ–‡ä»¶
        :param valid_name_pattern: è¦åˆå¹¶çš„csvæ–‡ä»¶å(åŒ…å«åç¼€)è¦æ»¡è¶³çš„æ­£åˆ™è¡¨è¾¾å¼
        """
        # å°†æ”¯ä»˜å®çš„åˆ—åæ”¹ä¸ºè·Ÿå¾®ä¿¡ä¸€è‡´
        rename_cols = {'äº¤æ˜“åˆ†ç±»': 'äº¤æ˜“ç±»å‹',
                       'å•†å“è¯´æ˜': 'å•†å“',
                       'é‡‘é¢': 'é‡‘é¢(å…ƒ)',
                       'æ”¶/ä»˜æ¬¾æ–¹å¼': 'æ”¯ä»˜æ–¹å¼',
                       'äº¤æ˜“çŠ¶æ€': 'å½“å‰çŠ¶æ€',
                       'äº¤æ˜“è®¢å•å·': 'äº¤æ˜“å•å·',
                       'å•†å®¶è®¢å•å·': 'å•†æˆ·å•å·'}

        # åˆå¹¶æ‰€æœ‰å¾®ä¿¡çš„è´¦å•è®°å½•
        _df_zfb = CSVUtil.merge_csv_in_dir(self.csv_dir, '', self.unique_col, rename_cols=rename_cols, usecols=self.usecols,
                                           skip_rows=24, valid_name_pattern=valid_name_pattern, src_encoding='GBK')
        _df_zfb['é‡‘é¢(å…ƒ)'] = _df_zfb['é‡‘é¢(å…ƒ)'].apply(lambda x: float(str(x).replace('Â¥', '').replace(',', '')))  # å»æ‰ Â¥ ç¬¦å·å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        if self.ignore_family_card:
            _df_zfb = _df_zfb[~_df_zfb['æ”¯ä»˜æ–¹å¼'].str.contains('äº²å±å¡|äº²æƒ…å¡', na=False)]  # na=Falseè¡¨ç¤ºå°†NaNå€¼è§†ä¸ºä¸åŒ…å«

        if not CommonUtil.isNoneOrBlank(output_csv_name):
            CSVUtil.to_csv(_df_zfb, f'{self.csv_dir}/{output_csv_name}.csv')

        if self.df_zfb is not None:
            self.df_zfb = pd.concat([self.df_zfb, _df_zfb], ignore_index=True)
            self.df_zfb = CSVUtil.deduplicate(self.df_zfb, self.unique_col)
        else:
            self.df_zfb = _df_zfb
        return _df_zfb

    def merge_all_csv(self, df_list: Optional[List[pd.DataFrame]] = None, output_csv_name: str = 'merge_bill_all', force_merge: bool = False) -> pd.DataFrame:
        """
        :param df_list: å¾…åˆå¹¶çš„liståˆ—è¡¨, è‹¥ä¼ ç©º,é»˜è®¤åˆå¹¶çš„æ˜¯ self.df_wx  å’Œ  self.df_zfb
        :param output_csv_name: åˆå¹¶å¾®ä¿¡è´¦å•åç”Ÿæˆçš„csvæ–‡ä»¶å, è‹¥ä¼ ç©º, åˆ™ä¸ä¿å­˜æˆæ–‡ä»¶
        :param force_merge: è‹¥ output_csv_name æ–‡ä»¶å·²å­˜åœ¨, æ˜¯å¦ä»éœ€è¦é‡æ–°æ±‡æ€»ç»Ÿè®¡
        """
        output_csv_path = f'{self.csv_dir}/{output_csv_name}.csv'
        need_save = not FileUtil.isFileExist(output_csv_path) or force_merge
        if CommonUtil.isNoneOrBlank(df_list):
            if FileUtil.isFileExist(output_csv_path) and not force_merge:
                CommonUtil.printLog(f'merge_all_csv ç›´æ¥è¯»å–å·²æ±‡æ€»çš„æ•°æ®æ–‡ä»¶: {output_csv_path}')
                df_list = [CSVUtil.read_csv(output_csv_path)]
            else:
                if self.df_wx is None:
                    self.merge_wx_csv()
                if self.df_zfb is None:
                    self.merge_zfb_csv()

                df_list = [self.df_wx, self.df_zfb]
                CommonUtil.printLog(f'merge_all_csv åˆå¹¶å¾®ä¿¡å’Œæ”¯ä»˜å®è´¦å•æ•°æ®: {len(df_list)} ä¸ª')

        df_list = [x for x in df_list if not CommonUtil.isNoneOrBlank(x)]
        if CommonUtil.isNoneOrBlank(df_list):
            _df_all = pd.DataFrame()
        else:
            # åˆå¹¶å¾®ä¿¡å’Œæ”¯ä»˜å®æ•°æ®, å¾—åˆ°æ€»æ”¯å‡ºè¡¨
            _df_all = pd.concat(df_list, ignore_index=True)
            _df_all['é‡‘é¢(å…ƒ)'] = _df_all['é‡‘é¢(å…ƒ)'].apply(lambda x: float(str(x).replace('Â¥', '').replace(',', '')))  # å»æ‰ Â¥ ç¬¦å·å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            _df_all = CSVUtil.deduplicate(_df_all, self.unique_col)
            if not CommonUtil.isNoneOrBlank(output_csv_name) and need_save:
                CSVUtil.to_csv(_df_all, f'{self.csv_dir}/{output_csv_name}.csv', index=False)
        self.df_all = _df_all
        return self.df_all

    @staticmethod
    def find_matching_counterparties(df: pd.DataFrame, pattern: str, col: str = 'äº¤æ˜“å¯¹æ–¹') -> List[str]:
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æŒ‡å®šåˆ—(é»˜è®¤'äº¤æ˜“å¯¹æ–¹'åˆ—)ä¸­çš„æ‰€æœ‰å¯èƒ½çš„åå­—

        å‚æ•°:
        - df: åŒ…å«äº¤æ˜“è®°å½•çš„æ•°æ®æ¡†
        - pattern: ç”¨äºåŒ¹é…çš„æ­£åˆ™è¡¨è¾¾å¼å­—ç¬¦ä¸²

        è¿”å›:
        - åŒ¹é…åˆ°çš„äº¤æ˜“å¯¹æ–¹åç§°åˆ—è¡¨ï¼ˆå»é‡åï¼‰
        """
        # è·å–æ‰€æœ‰å”¯ä¸€çš„äº¤æ˜“å¯¹æ–¹åç§°
        unique_names = df[col].unique()

        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        regex = re.compile(pattern)

        # æ‰¾å‡ºæ‰€æœ‰åŒ¹é…çš„åç§°
        matched_names = [name for name in unique_names if regex.search(name)]

        return matched_names

    @staticmethod
    def analyze_by_counterparty(df: pd.DataFrame, decimals: int = 0) -> pd.DataFrame:
        """
        æ ¹æ®äº¤æ˜“æ–¹åç§°å’Œæ”¶æ”¯å…³ç³»è¿›è¡Œåˆ†ç±»å’Œç»Ÿè®¡, æ±‡æ€»æ‰€æœ‰æ•°æ®
        :param decimals: é‡‘é¢è¦ä¿ç•™çš„å°æ•°ä½æ•°
        è¾“å‡ºç»“æœ:
            äº¤æ˜“å¯¹æ–¹: å•†å®¶æˆ–ä¸ªäººåç§°
            æ€»æ”¶å…¥: ä»è¯¥å¯¹æ–¹è·å¾—çš„æ”¶å…¥æ€»é¢
            æ€»æ”¯å‡º: å‘è¯¥å¯¹æ–¹æ”¯ä»˜çš„æ”¯å‡ºæ€»é¢
            äº¤æ˜“æ¬¡æ•°: ä¸è¯¥å¯¹æ–¹çš„äº¤æ˜“æ€»æ¬¡æ•°
            å‡€é¢: æ”¶å…¥å‡å»æ”¯å‡ºçš„ä½™é¢
        """

        # æŒ‰äº¤æ˜“å¯¹æ–¹å’Œæ”¶æ”¯ç±»å‹åˆ†ç»„
        grouped = df.groupby(['äº¤æ˜“å¯¹æ–¹', 'æ”¶/æ”¯'])['é‡‘é¢(å…ƒ)'].agg(['sum', 'count']).reset_index()

        # é€è§†è¡¨æ ¼å¼åŒ–
        pivot_table = grouped.pivot(index='äº¤æ˜“å¯¹æ–¹', columns='æ”¶/æ”¯', values='sum').fillna(0)
        count_table = grouped.pivot(index='äº¤æ˜“å¯¹æ–¹', columns='æ”¶/æ”¯', values='count').fillna(0)

        # åˆå¹¶ç»“æœ
        result = pd.DataFrame({
            'æ”¶å…¥': pivot_table.get('æ”¶å…¥', pd.Series(0, index=pivot_table.index)),
            'æ”¯å‡º': pivot_table.get('æ”¯å‡º', pd.Series(0, index=pivot_table.index)),
            'æ”¶å…¥æ¬¡æ•°': count_table.get('æ”¶å…¥', pd.Series(0, index=count_table.index)).astype(int),
            'æ”¯å‡ºæ¬¡æ•°': count_table.get('æ”¯å‡º', pd.Series(0, index=count_table.index)).astype(int)
        }).fillna(0)

        result['å‡€é¢'] = result['æ”¶å…¥'] - result['æ”¯å‡º']

        # é‡ç½®ç´¢å¼•ï¼Œå°†"äº¤æ˜“å¯¹æ–¹"å˜æˆæ™®é€šåˆ—
        result = result.reset_index()
        result = result.sort_values('æ”¯å‡º', ascending=False)

        # # å¯¹é™¤'äº¤æ˜“å¯¹æ–¹' å¤–çš„å„åˆ—æ•°æ®è¿›è¡Œæ±‡æ€»æ±‚å’Œ
        # summary = result.loc[:, result.columns != 'äº¤æ˜“å¯¹æ–¹'].sum()  # è®¡ç®—é™¤'äº¤æ˜“å¯¹æ–¹'å¤–å…¶ä»–åˆ—çš„å’Œ
        # summary_row = pd.DataFrame([['åˆè®¡'] + summary.tolist()], columns=['äº¤æ˜“å¯¹æ–¹'] + list(summary.index))  # åˆ›å»ºæ±‡æ€»è¡Œ
        # result = pd.concat([result, summary_row], ignore_index=True)  # å°†æ±‡æ€»è¡Œæ·»åŠ åˆ°åŸDataFrame

        result['æ”¶å…¥'] = result['æ”¶å…¥'].round(decimals)
        result['æ”¯å‡º'] = result['æ”¯å‡º'].round(decimals)
        result['å‡€é¢'] = result['å‡€é¢'].round(decimals)

        return result

    @staticmethod
    def query_counterparty_stats(df: pd.DataFrame, counterparty_names: List[str], decimals: int = 0) -> Dict:
        """
        æŸ¥è¯¢ç‰¹å®šäº¤æ˜“å¯¹æ–¹çš„ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¹´åº¦å’Œæœˆåº¦ç»Ÿè®¡

        å‚æ•°:
        - df: æ•°æ®æ¡†
        - counterparty_names: äº¤æ˜“å¯¹æ–¹åç§°åˆ—è¡¨, è‹¥ä¸ç¡®å®š, å¯ä»¥é€šè¿‡ find_matching_counterparties(...) æ–¹æ³•æ­£åˆ™åŒ¹é…å¾—åˆ°
        - param decimals: é‡‘é¢è¦ä¿ç•™çš„å°æ•°ä½æ•°

        è¿”å›:
        - åŒ…å«æ€»ä½“ã€å¹´åº¦å’Œæœˆåº¦ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        CommonUtil.printLog(f'query_counterparty_stats æŸ¥è¯¢äº¤æ˜“æ–¹: {counterparty_names}')
        counterparty_name = counterparty_names[0]
        party_transactions = df[df['äº¤æ˜“å¯¹æ–¹'].isin(counterparty_names)].copy()

        if party_transactions.empty:
            return {"message": f"æœªæ‰¾åˆ°ä¸ {counterparty_name} çš„äº¤æ˜“è®°å½•"}

        # æå–å¹´ä»½å’Œæœˆä»½ - ä¿®å¤æ—¥æœŸè½¬æ¢è­¦å‘Š
        try:
            party_transactions['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(party_transactions['äº¤æ˜“æ—¶é—´'],
                                                            format='%Y-%m-%d %H:%M:%S',
                                                            errors='coerce')
            # å¦‚æœä¸Šé¢çš„æ ¼å¼ä¸åŒ¹é…ï¼Œåˆ™å°è¯•è‡ªåŠ¨æ¨æ–­
            if party_transactions['äº¤æ˜“æ—¶é—´'].isna().all():
                party_transactions['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(party_transactions['äº¤æ˜“æ—¶é—´'])
        except:
            party_transactions['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(party_transactions['äº¤æ˜“æ—¶é—´'])

        party_transactions['å¹´ä»½'] = party_transactions['äº¤æ˜“æ—¶é—´'].dt.year
        party_transactions['æœˆä»½'] = party_transactions['äº¤æ˜“æ—¶é—´'].dt.month

        # æ€»ä½“ç»Ÿè®¡
        income_amount = party_transactions[party_transactions['æ”¶/æ”¯'] == 'æ”¶å…¥']['é‡‘é¢(å…ƒ)'].sum()
        expense_amount = party_transactions[party_transactions['æ”¶/æ”¯'] == 'æ”¯å‡º']['é‡‘é¢(å…ƒ)'].sum()
        transaction_count = len(party_transactions)

        # å¹´åº¦ç»Ÿè®¡
        yearly_stats = party_transactions.groupby(['å¹´ä»½', 'æ”¶/æ”¯'])['é‡‘é¢(å…ƒ)'].agg(['sum', 'count']).unstack(fill_value=0)
        # è·å–å®é™…çš„åˆ—æ•°
        col_count = len(yearly_stats.columns)
        # æ ¹æ®å®é™…åˆ—æ•°è®¾ç½®åˆ—å
        if col_count == 4:
            yearly_stats.columns = ['æ”¶å…¥é‡‘é¢', 'æ”¶å…¥æ¬¡æ•°', 'æ”¯å‡ºé‡‘é¢', 'æ”¯å‡ºæ¬¡æ•°']
        else:
            # å¦‚æœåˆ—æ•°ä¸åŒ¹é…ï¼Œä½¿ç”¨åŸå§‹çš„å¤šçº§åˆ—å
            yearly_stats.columns = [f"{col[0]}_{col[1]}" for col in yearly_stats.columns]

        yearly_stats = yearly_stats.reset_index()  # å°†å¹´ä»½ä»ç´¢å¼•è½¬ä¸ºåˆ—
        if 'æ”¶å…¥é‡‘é¢' in yearly_stats.columns and 'æ”¯å‡ºé‡‘é¢' in yearly_stats.columns:
            yearly_stats['å‡€é¢'] = yearly_stats['æ”¶å…¥é‡‘é¢'] - yearly_stats['æ”¯å‡ºé‡‘é¢']
        else:
            yearly_stats['å‡€é¢'] = yearly_stats.get('sum_æ”¶å…¥', 0) - yearly_stats.get('sum_æ”¯å‡º', 0)
        yearly_stats = yearly_stats.sort_values('å¹´ä»½', ascending=False)

        # æœˆåº¦ç»Ÿè®¡
        monthly_stats = party_transactions.groupby(['å¹´ä»½', 'æœˆä»½', 'æ”¶/æ”¯'])['é‡‘é¢(å…ƒ)'].agg(['sum', 'count']).unstack(fill_value=0)
        # è·å–å®é™…çš„åˆ—æ•°
        col_count = len(monthly_stats.columns)
        # æ ¹æ®å®é™…åˆ—æ•°è®¾ç½®åˆ—å
        if col_count == 4:
            monthly_stats.columns = ['æ”¶å…¥é‡‘é¢', 'æ”¶å…¥æ¬¡æ•°', 'æ”¯å‡ºé‡‘é¢', 'æ”¯å‡ºæ¬¡æ•°']
        else:
            # å¦‚æœåˆ—æ•°ä¸åŒ¹é…ï¼Œä½¿ç”¨åŸå§‹çš„å¤šçº§åˆ—å
            monthly_stats.columns = [f"{col[0]}_{col[1]}" for col in monthly_stats.columns]

        monthly_stats = monthly_stats.reset_index()  # å°†å¹´ä»½å’Œæœˆä»½ä»ç´¢å¼•è½¬ä¸ºåˆ—
        if 'æ”¶å…¥é‡‘é¢' in monthly_stats.columns and 'æ”¯å‡ºé‡‘é¢' in monthly_stats.columns:
            monthly_stats['å‡€é¢'] = monthly_stats['æ”¶å…¥é‡‘é¢'] - monthly_stats['æ”¯å‡ºé‡‘é¢']
        else:
            monthly_stats['å‡€é¢'] = monthly_stats.get('sum_æ”¶å…¥', 0) - monthly_stats.get('sum_æ”¯å‡º', 0)
        monthly_stats = monthly_stats.sort_values(['å¹´ä»½', 'æœˆä»½'], ascending=False)

        # åªä¿ç•™æ•´æ•°, å››èˆäº”å…¥
        pending_cols = ['æ”¶å…¥é‡‘é¢', 'æ”¯å‡ºé‡‘é¢', 'å‡€é¢', 'sum_ä¸è®¡æ”¶æ”¯', 'sum_æ”¯å‡º', 'sum_æ”¶å…¥']
        for df_item in [yearly_stats, monthly_stats]:
            for col in pending_cols:
                if col in df_item.columns:
                    df_item[col] = df_item[col].round(decimals)

        return {
            'äº¤æ˜“å¯¹æ–¹': counterparty_name,
            'æ€»æ”¶å…¥': income_amount.round(decimals),
            'æ€»æ”¯å‡º': expense_amount.round(decimals),
            'å‡€é¢': (income_amount - expense_amount).round(decimals),
            'äº¤æ˜“æ¬¡æ•°': transaction_count,
            'å¹´åº¦ç»Ÿè®¡': yearly_stats,
            'æœˆåº¦ç»Ÿè®¡': monthly_stats,
            'è¯¦ç»†è®°å½•': party_transactions
        }

    @staticmethod
    def analyze_overall_by_time(df: pd.DataFrame, decimals: int = 0) -> Dict[str, pd.DataFrame]:
        """
        ç»Ÿè®¡æ•´ä¸ªæ•°æ®é›†çš„æ€»ä½“æ”¶æ”¯æƒ…å†µï¼ŒæŒ‰å¹´å’ŒæŒ‰æœˆè¿›è¡Œæ±‡æ€»
        :param df: æ•°æ®æº
        :param decimals: æ€»æ”¶å…¥/æ€»æ”¯å‡º/æ€»å‡€é¢ è¦ä¿ç•™å‡ ä½å°æ•°,é»˜è®¤åªä¿ç•™æ•´æ•°
        è¿”å›ç»“æœåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š
        - å¹´åº¦ç»Ÿè®¡: æŒ‰å¹´ä»½æ±‡æ€»çš„æ€»ä½“æ”¶æ”¯æƒ…å†µ
        - æœˆåº¦ç»Ÿè®¡: æŒ‰æœˆä»½æ±‡æ€»çš„æ€»ä½“æ”¶æ”¯æƒ…å†µ
        """
        # é¦–å…ˆè½¬æ¢æ—¥æœŸåˆ—ï¼ŒæŒ‡å®šæ—¥æœŸæ ¼å¼ä»¥é¿å…è­¦å‘Š
        df_with_date = df.copy()
        try:
            # å°è¯•å¸¸è§çš„æ—¥æœŸæ ¼å¼
            df_with_date['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(df_with_date['äº¤æ˜“æ—¶é—´'],
                                                      format='%Y-%m-%d %H:%M:%S',
                                                      errors='coerce')
            # å¦‚æœä¸Šé¢çš„æ ¼å¼ä¸åŒ¹é…ï¼Œåˆ™å°è¯•è‡ªåŠ¨æ¨æ–­
            if df_with_date['äº¤æ˜“æ—¶é—´'].isna().all():
                df_with_date['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(df_with_date['äº¤æ˜“æ—¶é—´'])
        except:
            df_with_date['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(df_with_date['äº¤æ˜“æ—¶é—´'])

        df_with_date['å¹´ä»½'] = df_with_date['äº¤æ˜“æ—¶é—´'].dt.year
        df_with_date['æœˆä»½'] = df_with_date['äº¤æ˜“æ—¶é—´'].dt.month

        # æŒ‰å¹´ä»½ç»Ÿè®¡
        yearly_grouped = df_with_date.groupby(['å¹´ä»½', 'æ”¶/æ”¯'])['é‡‘é¢(å…ƒ)'].agg(['sum', 'count']).reset_index()
        yearly_pivot_sum = yearly_grouped.pivot_table(
            index='å¹´ä»½',
            columns='æ”¶/æ”¯',
            values='sum',
            fill_value=0
        ).fillna(0)

        yearly_pivot_count = yearly_grouped.pivot_table(
            index='å¹´ä»½',
            columns='æ”¶/æ”¯',
            values='count',
            fill_value=0
        ).fillna(0)

        # åˆå¹¶å¹´åº¦ç»Ÿè®¡
        yearly_stats = pd.DataFrame({
            'æ€»æ”¶å…¥': yearly_pivot_sum.get('æ”¶å…¥', pd.Series(0, index=yearly_pivot_sum.index)),
            'æ€»æ”¯å‡º': yearly_pivot_sum.get('æ”¯å‡º', pd.Series(0, index=yearly_pivot_sum.index)),
            'æ€»æ”¶å…¥æ¬¡æ•°': yearly_pivot_count.get('æ”¶å…¥', pd.Series(0, index=yearly_pivot_count.index)).astype(int),
            'æ€»æ”¯å‡ºæ¬¡æ•°': yearly_pivot_count.get('æ”¯å‡º', pd.Series(0, index=yearly_pivot_count.index)).astype(int)
        }).fillna(0)
        yearly_stats['æ€»å‡€é¢'] = yearly_stats['æ€»æ”¶å…¥'] - yearly_stats['æ€»æ”¯å‡º']
        yearly_stats = yearly_stats.reset_index()
        yearly_stats = yearly_stats.sort_values('å¹´ä»½', ascending=False)

        # å¯¹é™¤'å¹´ä»½' å¤–çš„å„åˆ—æ•°æ®è¿›è¡Œæ±‡æ€»æ±‚å’Œ
        summary = yearly_stats.loc[:, yearly_stats.columns != 'å¹´ä»½'].sum()  # è®¡ç®—é™¤'å¹´ä»½'å¤–å…¶ä»–åˆ—çš„å’Œ
        summary_row = pd.DataFrame([['åˆè®¡'] + summary.tolist()], columns=['å¹´ä»½'] + list(summary.index))  # åˆ›å»ºæ±‡æ€»è¡Œ
        yearly_stats = pd.concat([yearly_stats, summary_row], ignore_index=True)  # å°†æ±‡æ€»è¡Œæ·»åŠ åˆ°åŸDataFrame

        # æŒ‰æœˆä»½ç»Ÿè®¡
        monthly_grouped = df_with_date.groupby(['å¹´ä»½', 'æœˆä»½', 'æ”¶/æ”¯'])['é‡‘é¢(å…ƒ)'].agg(['sum', 'count']).reset_index()
        monthly_pivot_sum = monthly_grouped.pivot_table(
            index=['å¹´ä»½', 'æœˆä»½'],
            columns='æ”¶/æ”¯',
            values='sum',
            fill_value=0
        ).fillna(0)
        monthly_pivot_count = monthly_grouped.pivot_table(
            index=['å¹´ä»½', 'æœˆä»½'],
            columns='æ”¶/æ”¯',
            values='count',
            fill_value=0
        ).fillna(0)

        # åˆå¹¶æœˆåº¦ç»Ÿè®¡
        monthly_stats = pd.DataFrame({
            'æ€»æ”¶å…¥': monthly_pivot_sum.get('æ”¶å…¥', pd.Series(0, index=monthly_pivot_sum.index)),
            'æ€»æ”¯å‡º': monthly_pivot_sum.get('æ”¯å‡º', pd.Series(0, index=monthly_pivot_sum.index)),
            'æ€»æ”¶å…¥æ¬¡æ•°': monthly_pivot_count.get('æ”¶å…¥', pd.Series(0, index=monthly_pivot_count.index)).astype(int),
            'æ€»æ”¯å‡ºæ¬¡æ•°': monthly_pivot_count.get('æ”¯å‡º', pd.Series(0, index=monthly_pivot_count.index)).astype(int)
        }).fillna(0)
        monthly_stats['æ€»å‡€é¢'] = monthly_stats['æ€»æ”¶å…¥'] - monthly_stats['æ€»æ”¯å‡º']
        monthly_stats = monthly_stats.reset_index()
        monthly_stats = monthly_stats.sort_values(['å¹´ä»½', 'æœˆä»½'], ascending=[False, False])

        # å¯¹é™¤'å¹´ä»½'/'æœˆä»½' å¤–çš„å„åˆ—æ•°æ®è¿›è¡Œæ±‡æ€»æ±‚å’Œ
        summary = pd.DataFrame({'å¹´ä»½': ['åˆè®¡'], 'æœˆä»½': ['']})  # åˆ›å»ºæ±‡æ€»è¡Œ
        for col in monthly_stats.columns:
            if col not in ['å¹´ä»½', 'æœˆä»½']:  # å¯¹é™¤'å¹´ä»½'å’Œ'æœˆä»½'å¤–çš„åˆ—æ±‚å’Œ
                summary[col] = [monthly_stats[col].sum()]
        monthly_stats = pd.concat([monthly_stats, summary], ignore_index=True)  # å°†æ±‡æ€»è¡Œæ·»åŠ åˆ°åŸDataFrame

        # åªä¿ç•™æ•´æ•°, å››èˆäº”å…¥
        for df_item in [yearly_stats, monthly_stats]:
            df_item['æ€»æ”¶å…¥'] = df_item['æ€»æ”¶å…¥'].round(decimals)
            df_item['æ€»æ”¯å‡º'] = df_item['æ€»æ”¯å‡º'].round(decimals)
            df_item['æ€»å‡€é¢'] = df_item['æ€»å‡€é¢'].round(decimals)

        return {
            'å¹´åº¦ç»Ÿè®¡': yearly_stats,
            'æœˆåº¦ç»Ÿè®¡': monthly_stats
        }

    @staticmethod
    def merge_counterparty_stats(stats_list):
        """
        åˆå¹¶å¤šä¸ªäº¤æ˜“å¯¹æ–¹çš„ç»Ÿè®¡ç»“æœ,ä¸»è¦ç”¨äºåŒä¸€ä¸ªäººä½†æœ‰å¤šä¸ªåç§°çš„åœºæ™¯

        å‚æ•°:
        - stats_list: åŒ…å«å¤šä¸ªç»Ÿè®¡å­—å…¸çš„åˆ—è¡¨

        è¿”å›:
        - åˆå¹¶åçš„ç»Ÿè®¡å­—å…¸
        """
        if not stats_list:
            return {}

        # åˆå§‹åŒ–åˆå¹¶ç»“æœ
        merged = {
            'äº¤æ˜“å¯¹æ–¹': stats_list[0]['äº¤æ˜“å¯¹æ–¹'],  # å¯ä»¥ä½¿ç”¨è§„èŒƒåç§°
            'æ€»æ”¶å…¥': 0,
            'æ€»æ”¯å‡º': 0,
            'å‡€é¢': 0,
            'äº¤æ˜“æ¬¡æ•°': 0,
            'è¯¦ç»†è®°å½•': pd.DataFrame()  # å¦‚æœéœ€è¦åˆå¹¶è¯¦ç»†è®°å½•
        }

        # éå†æ‰€æœ‰ç»Ÿè®¡ç»“æœè¿›è¡Œç´¯åŠ 
        for stat in stats_list:
            merged['æ€»æ”¶å…¥'] += stat.get('æ€»æ”¶å…¥', 0)
            merged['æ€»æ”¯å‡º'] += stat.get('æ€»æ”¯å‡º', 0)
            merged['å‡€é¢'] += stat.get('å‡€é¢', 0)
            merged['äº¤æ˜“æ¬¡æ•°'] += stat.get('äº¤æ˜“æ¬¡æ•°', 0)

            # å¦‚æœæœ‰è¯¦ç»†è®°å½•ï¼Œåˆå¹¶DataFrame
            if 'è¯¦ç»†è®°å½•' in stat and not stat['è¯¦ç»†è®°å½•'].empty:
                merged['è¯¦ç»†è®°å½•'] = pd.concat([
                    merged['è¯¦ç»†è®°å½•'],
                    stat['è¯¦ç»†è®°å½•']
                ], ignore_index=True)

        return merged

    @staticmethod
    def visualize_crop_area(pdf_path, crop_box=(0, 150, 0, 0), save_img_path="crop_preview.png", resolution=150):
        """
        å¯è§†åŒ–PDFè£å‰ªåŒºåŸŸï¼ˆç²¾å‡†è°ƒæ•´è£å‰ªå‚æ•°ï¼‰
        1. ç”Ÿæˆç¬¬ä¸€é¡µçš„æˆªå›¾ï¼Œæ ‡æ³¨æ‰€æœ‰æ–‡æœ¬çš„åæ ‡
        2. ç»˜åˆ¶è£å‰ªåŒºåŸŸçš„çº¢è‰²è¾¹æ¡†ï¼Œç›´è§‚å±•ç¤ºè£å‰ªèŒƒå›´
        3. ä¿å­˜é¢„è§ˆå›¾åˆ°æœ¬åœ°ï¼Œå¯æ ¹æ®é¢„è§ˆå›¾è°ƒæ•´è£å‰ªå‚æ•°
        æ‰“å¼€ç”Ÿæˆçš„ crop_preview.pngï¼Œä½ ä¼šçœ‹åˆ°ï¼š
        ğŸŸ¥ çº¢è‰²åŠé€æ˜åŒºåŸŸï¼šå½“å‰è£å‰ªèŒƒå›´
        ğŸŸ¨ é»„è‰²æ ‡æ³¨æ¡†ï¼šå…³é”®æ–‡æœ¬ï¼ˆæ—¥æœŸ / é‡‘é¢ï¼‰çš„åæ ‡
        ğŸ“ é¢„è§ˆå›¾æ ‡é¢˜ï¼šå½“å‰è£å‰ªå‚æ•°
        ğŸ“œ æ§åˆ¶å°ï¼šè£å‰ªåçš„æ–‡æœ¬é¢„è§ˆï¼ˆèƒ½çœ‹åˆ°æ˜¯å¦åªä¿ç•™äº†è¡¨æ ¼ï¼‰
        :param pdf_path: æ‹›è¡Œæµæ°´PDFè·¯å¾„
        :param crop_box: å¾…æµ‹è¯•çš„è£å‰ªå‚æ•° (left, top, right, bottom)
                         å¯¹äºrightå’Œbottomå°ºå¯¸, è‹¥å°äº0, åˆ™è¡¨ç¤ºä»¥é¡µé¢è¾¹ç•Œå†…ç¼©æŒ‡å®šå°ºå¯¸
        :param save_img_path: é¢„è§ˆå›¾ä¿å­˜è·¯å¾„
        :param resolution: é¢„è§ˆå›¾åˆ†è¾¨ç‡ï¼ˆdpiï¼‰ï¼Œä¸å½±å“è£å‰ªç²¾åº¦
        """
        import pdfplumber
        import matplotlib.pyplot as plt
        import matplotlib.patches as patches
        import matplotlib.font_manager as fm
        from PIL import Image

        # æ–¹æ¡ˆAï¼šä½¿ç”¨ç³»ç»Ÿè‡ªå¸¦çš„ä¸­æ–‡å­—ä½“ï¼ˆæ— éœ€é¢å¤–å®‰è£…ï¼‰
        font_path = CommonUtil.find_system_chinese_font()
        font_prop = None
        if font_path:
            font_prop = fm.FontProperties(fname=font_path)
            plt.rcParams['font.sans-serif'] = [font_prop.get_name()]

        # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
        plt.rcParams['axes.unicode_minus'] = False

        # 1. æ‰“å¼€PDFå¹¶è·å–ç¬¬ä¸€é¡µ
        with pdfplumber.open(pdf_path) as pdf:
            page = pdf.pages[0]
            # PDFåŸå§‹å°ºå¯¸ï¼ˆptï¼‰ï¼šwidth=é¡µé¢å®½åº¦ï¼Œheight=é¡µé¢é«˜åº¦
            pdf_width_pt = page.width
            pdf_height_pt = page.height

            # è¡¥å…¨è£å‰ªæ¡†çš„rightå’Œbottomï¼ˆé»˜è®¤ç”¨é¡µé¢å®½é«˜ï¼‰
            left = crop_box[0]
            top = crop_box[1]
            right = crop_box[2] if crop_box[2] > 0 else page.width + crop_box[2]
            bottom = crop_box[3] if crop_box[3] > 0 else page.height + crop_box[3]
            # right = crop_box[2] if crop_box[2] != 0 else page.width
            # bottom = crop_box[3] if crop_box[3] != 0 else page.height - 50

            crop_box_pt = (left, top, right, bottom)

            # ========== 3. ç”Ÿæˆé¢„è§ˆå›¾å¹¶è®¡ç®—åƒç´ /ptæ¢ç®—æ¯”ä¾‹ï¼ˆæ ¸å¿ƒæ ¡å‡†ï¼‰ ==========
            # ç”Ÿæˆé¢„è§ˆå›¾ï¼ˆresolutionä»…å½±å“å›¾ç‰‡æ¸…æ™°åº¦ï¼Œä¸å½±å“åæ ‡ï¼‰
            img = page.to_image(resolution=resolution)
            img_array = np.array(img.original)
            # é¢„è§ˆå›¾åƒç´ å°ºå¯¸
            img_width_px = img_array.shape[1]
            img_height_px = img_array.shape[0]
            # è®¡ç®—æ¢ç®—æ¯”ä¾‹ï¼š1pt = å¤šå°‘px
            px_per_pt_x = img_width_px / pdf_width_pt
            px_per_pt_y = img_height_px / pdf_height_pt

            # ========== 4. å°†PDFè£å‰ªåæ ‡ï¼ˆptï¼‰æ¢ç®—ä¸ºé¢„è§ˆå›¾åæ ‡ï¼ˆpxï¼‰ ==========
            crop_box_px = (
                crop_box_pt[0] * px_per_pt_x,  # left (px)
                crop_box_pt[1] * px_per_pt_y,  # top (px)
                crop_box_pt[2] * px_per_pt_x,  # right (px)
                crop_box_pt[3] * px_per_pt_y  # bottom (px)
            )

            # ========== 5. ç»˜åˆ¶é¢„è§ˆå›¾ï¼ˆç²¾å‡†å¯¹é½ï¼‰ ==========
            fig, ax = plt.subplots(1, figsize=(15, 10))
            ax.imshow(img_array)

            # ç»˜åˆ¶è£å‰ªåŒºåŸŸï¼ˆçº¢è‰²è¾¹æ¡†ï¼ŒåŠé€æ˜ï¼‰
            rect = patches.Rectangle(
                (crop_box_px[0], crop_box_px[1]),  # å·¦ä¸Šè§’ï¼ˆpxï¼‰
                crop_box_px[2] - crop_box_px[0],  # å®½åº¦ï¼ˆpxï¼‰
                crop_box_px[3] - crop_box_px[1],  # é«˜åº¦ï¼ˆpxï¼‰
                linewidth=3,
                edgecolor='red',
                facecolor='red',
                alpha=0.2
            )
            ax.add_patch(rect)

            # ========== 6. æ ‡æ³¨å…³é”®æ–‡æœ¬ï¼ˆPDFåŸå§‹åæ ‡+é¢„è§ˆå›¾åƒç´ åæ ‡ï¼‰ ==========
            for word in page.extract_words():
                if any(key in word['text'] for key in ['Date', 'Balance', 'Party']):
                    # æ–‡æœ¬çš„PDFåæ ‡ï¼ˆptï¼‰â†’ é¢„è§ˆå›¾åæ ‡ï¼ˆpxï¼‰
                    word_x_px = word['x0'] * px_per_pt_x
                    word_y_px = word['top'] * px_per_pt_y
                    # æ ‡æ³¨æ–‡æœ¬ï¼ˆåŒæ—¶æ˜¾ç¤ºPDFåŸå§‹åæ ‡å’Œé¢„è§ˆå›¾åƒç´ åæ ‡ï¼‰
                    ax.text(
                        word_x_px, word_y_px,
                        f"{word['text']}\nPDFåæ ‡ï¼š({word['x0']:.0f},{word['top']:.0f}pt)\nåƒç´ åæ ‡ï¼š({word_x_px:.0f},{word_y_px:.0f}px)",
                        fontsize=8,
                        color='blue',
                        bbox=dict(boxstyle="round,pad=0.3", fc="yellow", alpha=0.7),
                        fontproperties=font_prop
                    )

            # ========== 7. ä¿å­˜é¢„è§ˆå›¾ + æ‰“å°å…³é”®ä¿¡æ¯ ==========
            ax.axis('off')
            plt.title(
                f"PDF Crop Preview (åˆ†è¾¨ç‡={resolution}dpi | è£å‰ªæ¡†PDFåæ ‡ï¼š{crop_box_pt})",
                fontsize=14,
                fontproperties=font_prop
            )
            plt.tight_layout()
            plt.savefig(save_img_path, dpi=resolution, bbox_inches='tight')
            plt.close()

            # æ‰“å°æ ¡å‡†ä¿¡æ¯
            print("=" * 60)
            print(f"âœ… ç²¾å‡†é¢„è§ˆå›¾å·²ä¿å­˜ï¼š{save_img_path}")
            print(f"ğŸ“ PDFåŸå§‹å°ºå¯¸ï¼š{pdf_width_pt:.0f}pt Ã— {pdf_height_pt:.0f}pt")
            print(f"ğŸ–¼ï¸ é¢„è§ˆå›¾å°ºå¯¸ï¼š{img_width_px}px Ã— {img_height_px}px")
            print(f"ğŸ” æ¢ç®—æ¯”ä¾‹ï¼š1pt = {px_per_pt_x:.4f}pxï¼ˆæ°´å¹³ï¼‰ | 1pt = {px_per_pt_y:.4f}pxï¼ˆå‚ç›´ï¼‰")
            print(f"ğŸ¯ å®é™…è£å‰ªå‚æ•°ï¼ˆPDFåæ ‡ï¼‰ï¼šleft={crop_box_pt[0]}pt, top={crop_box_pt[1]}pt, right={crop_box_pt[2]}pt, bottom={crop_box_pt[3]}pt")
            print("=" * 60)

            # éªŒè¯ï¼šæ‰“å°è£å‰ªåçš„æ–‡æœ¬ï¼ˆå®é™…è£å‰ªç»“æœï¼‰
            cropped_page = page.crop(crop_box_pt)
            cropped_text = cropped_page.extract_text()[:500]
            print("\nğŸ“ å®é™…è£å‰ªåçš„æ–‡æœ¬é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰ï¼š")
            print("-" * 50)
            print(cropped_text if cropped_text else "æ— æ–‡æœ¬")
            print("-" * 50)

    @staticmethod
    def cmb_pdf_to_csv(pdf_path, csv_path: Optional[str] = None, crop_box: Tuple[int] = (0, 0, 0, 0)):
        """
        çº¯Pythoné€‚é…æ‹›è¡Œæ— æ¡†çº¿æµæ°´PDFè½¬CSVï¼ˆè‹±æ–‡åˆ—åï¼‰
        :param pdf_path: æ‹›è¡ŒPDFæµæ°´è·¯å¾„
        :param csv_path: è¾“å‡ºCSVè·¯å¾„, éç©ºæ—¶æœ‰æ•ˆ
        :param crop_box: é¦–é¡µpdfçš„è£å‰ªåŒºåŸŸ,æ ¼å¼:left top right bottom, åªè¯†åˆ«è£å‰ªåŒºåŸŸå†…çš„ä¿¡æ¯
                         å…¶ä¸­: å¯¹äºrightå’Œbottomå°ºå¯¸, è‹¥å°äº0, åˆ™è¡¨ç¤ºä»¥é¡µé¢è¾¹ç•Œå†…ç¼©æŒ‡å®šå°ºå¯¸
        """
        if not CommonUtil.is_library_installed('pdfplumber'):
            CommonUtil.printLog(f'cmb_pdf_to_csv fail, please do: pip install pdfplumber')
            return None

        import pdfplumber
        all_data = []
        # ğŸŒŸ æŒ‰è¦æ±‚ä¿®æ”¹çš„è¡¨å¤´ï¼ˆå«ç©ºæ ¼çš„è‹±æ–‡å‘½åï¼‰
        header = [
            "Date",  # è®°è´¦æ—¥æœŸ
            "Currency",  # è´§å¸
            "Transaction Amount",  # äº¤æ˜“é‡‘é¢
            "Balance",  # è”æœºä½™é¢
            "Transaction Type",  # äº¤æ˜“æ‘˜è¦
            "Counter Party"  # å¯¹æ‰‹ä¿¡æ¯
        ]

        with pdfplumber.open(pdf_path) as pdf:
            for page_idx, page in enumerate(pdf.pages):
                # ========== æ ¸å¿ƒï¼šç¬¬ä¸€é¡µè£å‰ªï¼ˆé¿å¼€æ ‡é¢˜/è´¦æˆ·ä¿¡æ¯å¹²æ‰°ï¼‰ ==========
                if page_idx == 0:
                    left = crop_box[0]
                    top = crop_box[1]
                    right = crop_box[2] if crop_box[2] > 0 else page.width + crop_box[2]
                    bottom = crop_box[3] if crop_box[3] > 0 else page.height + crop_box[3]

                    # è£å‰ªå‚æ•°å¯æ ¹æ®ä½ çš„PDFå¾®è°ƒï¼š(å·¦, ä¸Š, å³, ä¸‹)
                    page = page.crop((left, top, right, bottom))

                # ========== æ— æ¡†çº¿è¡¨æ ¼ç²¾å‡†è¯†åˆ« ==========
                table = page.extract_table(table_settings={
                    "vertical_strategy": "text",  # æŒ‰æ–‡æœ¬å¯¹é½è¯†åˆ«åˆ—
                    "horizontal_strategy": "text",  # æŒ‰æ–‡æœ¬è¡Œé—´è·è¯†åˆ«è¡Œ
                    "text_y_tolerance": 2,  # ç¼©å°å‚ç›´å®¹å¿åº¦ï¼Œé¿å…è¡Œåˆå¹¶
                    "text_x_tolerance": 4,  # æŒ‰æ–‡æœ¬æ°´å¹³é—´éš”è¯†åˆ«åˆ—
                    "intersection_tolerance": 5,  # æ”¾å®½äº¤å‰ç‚¹å®¹å¿åº¦
                    "min_words_vertical": 2,  # å‚ç›´æ–¹å‘æœ€å°æœ‰æ•ˆè¯æ•°	åˆ¤å®šã€Œä¸€åˆ—æœ‰æ•ˆã€çš„æœ€å°æ–‡æœ¬æ•°é‡â†’ åªæœ‰å½“ä¸€åˆ—ä¸­è‡³å°‘åŒ…å« N ä¸ªæœ‰æ•ˆæ–‡æœ¬ï¼ˆéç©º / éç©º
                    "min_words_horizontal": 3  # æ°´å¹³æ–¹å‘æœ€å°æœ‰æ•ˆè¯æ•°
                })

                if table:
                    for row in table:
                        # æ¸…æ´—ç©ºå€¼å’Œç©ºæ ¼
                        cleaned_row = [cell.strip() if cell and cell.strip() else "" for cell in row]
                        # è¿‡æ»¤æ— æ•ˆè¡Œï¼ˆè‡³å°‘3ä¸ªæœ‰æ•ˆå­—æ®µ+éè¡¨å¤´ï¼‰
                        if len([c for c in cleaned_row if c]) >= 3 and cleaned_row != header:
                            all_data.append(cleaned_row)

        # ========== æ•°æ®æ¸…æ´—ä¸CSVå¯¼å‡º ==========
        # åœ¨åˆ›å»ºDataFrameä¹‹å‰æ·»åŠ æ•°æ®éªŒè¯
        if all_data:
            # è·å–å®é™…æ•°æ®çš„åˆ—æ•°
            actual_cols = len(all_data[0])
            print(f"å®é™…æå–çš„åˆ—æ•°: {actual_cols}: {all_data[0]}")

            # å¦‚æœå®é™…åˆ—æ•°ä¸headerä¸åŒ¹é…ï¼Œè°ƒæ•´header
            if actual_cols != len(header):
                # æ ¹æ®å®é™…åˆ—æ•°è°ƒæ•´header
                if actual_cols > len(header):
                    # å¦‚æœå®é™…åˆ—æ•°æ›´å¤šï¼Œæ·»åŠ é¢å¤–çš„åˆ—å
                    header.extend([f"Extra_{i}" for i in range(actual_cols - len(header))])
                else:
                    # å¦‚æœå®é™…åˆ—æ•°æ›´å°‘ï¼Œæˆªå–ç›¸åº”æ•°é‡çš„header
                    header = header[:actual_cols]

            # ç”¨æŒ‡å®šè¡¨å¤´åˆ›å»ºDataFrame
            df = pd.DataFrame(all_data, columns=header)

            # é‡‘é¢å­—æ®µè½¬ä¸ºæ•°å€¼å‹ï¼ˆé€‚é…Pandasç»Ÿè®¡ï¼‰
            for col in ["Transaction Amount", "Balance"]:
                df[col] = df[col].astype(str).str.replace(",", "").str.strip()
                df[col] = pd.to_numeric(df[col], errors="coerce")

            # æ—¥æœŸå­—æ®µæ ‡å‡†åŒ–ä¸ºdatetimeæ ¼å¼
            # æ—¥æœŸå­—æ®µæ ‡å‡†åŒ–ä¸ºdatetimeæ ¼å¼
            # å°è¯•å¸¸è§çš„æ—¥æœŸæ ¼å¼
            date_formats = [
                '%Y-%m-%d',  # 2023-12-25
                '%Y/%m/%d',  # 2023/12/25
                '%Y%m%d',  # 20231225
                '%d-%m-%Y',  # 25-12-2023
                '%d/%m/%Y',  # 25/12/2023
                '%Yå¹´%mæœˆ%dæ—¥',  # 2023å¹´12æœˆ25æ—¥
            ]

            # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼
            for fmt in date_formats:
                try:
                    df["Date"] = pd.to_datetime(df["Date"], format=fmt, errors='raise')
                    break  # å¦‚æœæˆåŠŸè§£æï¼Œè·³å‡ºå¾ªç¯
                except:
                    continue  # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ ¼å¼
            else:
                # å¦‚æœæ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•
                df["Date"] = pd.to_datetime(df["Date"], errors="coerce")

            # è¿‡æ»¤å…¨ç©ºè¡Œ
            df = df.dropna(how="all")

            # ä¿å­˜CSVï¼ˆUTF-8ç¼–ç é¿å…ä¹±ç ï¼‰
            CSVUtil.to_csv(df, csv_path)
            print(f"âœ… è½¬æ¢å®Œæˆï¼CSVå·²ä¿å­˜åˆ°ï¼š{csv_path}")
            return df
        else:
            print("âŒ æœªè§£æåˆ°æœ‰æ•ˆè¡¨æ ¼æ•°æ®ï¼Œè¯·æ£€æŸ¥PDFæ ¼å¼")
            return None


def main():
    target_csv_dir = os.path.dirname(os.path.abspath(__file__))  # å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    # target_csv_dir = './cache/wechat_zfb_bill'  # csvæ‰€åœ¨ç›®å½•

    target_csv_dir = CommonUtil.get_input_info(f'è¯·è¾“å…¥csvæ–‡ä»¶æ‰€åœ¨ç›®å½•(é»˜è®¤{target_csv_dir}): ', target_csv_dir)
    force_merge = CommonUtil.get_input_info('æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆå¹¶æ‰€æœ‰csvæ–‡ä»¶? y/n(é»˜è®¤): ', 'n') == 'y'
    ignore_family_card = CommonUtil.get_input_info('æ˜¯å¦å¿½ç•¥äº²æƒ…å¡æ•°æ®? y/n(é»˜è®¤): ', 'n') == 'y'

    billUtil = CSVBillUtil(target_csv_dir, ignore_family_card=ignore_family_card)
    df_all = billUtil.merge_all_csv(force_merge=force_merge)
    md_stats_file = f'{billUtil.csv_dir}/bill_stats_result.md'  # ç»“æœè¾“å‡ºmdæ–‡ä»¶è·¯å¾„
    backup_dir = f'{billUtil.csv_dir}/backup/'
    FileUtil.backup_file(md_stats_file, backup_dir)

    # # è®¾ç½®pandasæ˜¾ç¤ºé€‰é¡¹ä»¥æ”¹å–„è¡¨æ ¼å¯¹é½
    # pd.set_option('display.max_columns', None)  # æ˜¾ç¤ºæ‰€æœ‰åˆ—ï¼Œä¸ä¼šå‡ºç°åˆ—çœç•¥å·...
    # pd.set_option('display.max_rows', None)  # æœ€å¤šæ˜¾ç¤ºå¤šå°‘è¡Œè¡Œ,Noneè¡¨ç¤ºæ˜¾ç¤ºæ‰€æœ‰è¡Œ
    # pd.set_option('display.width', None)  # è‡ªåŠ¨é€‚é…å±å¹•å®½åº¦ï¼Œä¸é™åˆ¶æ€»å®½åº¦
    # pd.set_option('display.max_colwidth', 30)  # æ˜¾ç¤ºå•å…ƒæ ¼å…¨éƒ¨å†…å®¹ï¼ŒNoneè¡¨ç¤ºä¸æˆªæ–­ã€ä¸çœç•¥
    # pd.set_option('display.unicode.ambiguous_as_wide', True)  # ä¸­æ–‡å¯¹é½ä¸“ç”¨ï¼šä¸­æ–‡å 2å­—ç¬¦å®½åº¦
    # pd.set_option('display.unicode.east_asian_width', True)  # æ­£ç¡®å¤„ç†ä¸œäºšå­—ç¬¦å®½åº¦
    # pd.set_option('display.float_format', '{:,.2f}'.format)  # è®¾ç½®æµ®ç‚¹æ•°æ˜¾ç¤ºæ ¼å¼

    stats_result = CSVBillUtil.analyze_by_counterparty(df_all)

    stats_result_sorted = stats_result.sort_values('æ”¯å‡º', ascending=False)  # é™åºæ’åˆ—
    md_msg = f'## å¾®ä¿¡&æ”¯ä»˜å®æ•´ä½“æ”¶æ”¯æƒ…å†µ'
    md_msg += f'\n> å¼ºåˆ¶é‡æ–°åˆå¹¶={force_merge},å¿½ç•¥äº²æƒ…å¡:{ignore_family_card}\n'

    df_headN = stats_result_sorted.head(10).reset_index()
    summary = df_headN.loc[:, df_headN.columns != 'äº¤æ˜“å¯¹æ–¹'].sum()  # è®¡ç®—é™¤'äº¤æ˜“å¯¹æ–¹'å¤–å…¶ä»–åˆ—çš„å’Œ
    summary_row = pd.DataFrame([['åˆè®¡'] + summary.tolist()], columns=['äº¤æ˜“å¯¹æ–¹'] + list(summary.index))  # åˆ›å»ºæ±‡æ€»è¡Œ
    df_headN = pd.concat([df_headN, summary_row], ignore_index=True)  # å°†æ±‡æ€»è¡Œæ·»åŠ åˆ°åŸDataFrame
    md_msg += f'\n### æ•´ä½“æŒ‰æ”¯å‡ºé™åºæ’åˆ—å‰10é¡¹:\n{df_headN.to_markdown()}'

    # æ•´ä½“æŒ‰å¹´/æœˆç»Ÿè®¡æ”¶æ”¯æƒ…å†µ
    overall_time_stats = CSVBillUtil.analyze_overall_by_time(df_all)
    yearly_stats = overall_time_stats['å¹´åº¦ç»Ÿè®¡']
    md_msg += f'\n\n### æ•´ä½“æŒ‰å¹´æ”¶æ”¯æƒ…å†µ:\n{yearly_stats.to_markdown()}'
    # monthly_stats = overall_time_stats['æœˆåº¦ç»Ÿè®¡']
    # md_msg += f'\n\n### æ•´ä½“æŒ‰æœˆæ”¶æ”¯æƒ…å†µ:\n{monthly_stats.to_markdown()}'

    # æŸ¥è¯¢æŒ‡å®šäººå‘˜çš„äº¤æ˜“è®°å½•
    while True:
        name = CommonUtil.get_input_info('è¯·è¾“å…¥è¦æŸ¥è¯¢çš„äººå‘˜å§“å(æ­£åˆ™è¡¨è¾¾å¼),é»˜è®¤ä¸æŸ¥è¯¢å¹¶é€€å‡º: ', '')  # äººå‘˜å§“åæ­£åˆ™è¡¨è¾¾å¼, ä»Šå¹´åŒ¹é…å‡ºå¯èƒ½çš„å˜ä½“
        if CommonUtil.isNoneOrBlank(name):
            break

        names = CSVBillUtil.find_matching_counterparties(df_all, name)
        names_str = names[0]
        dict_special = CSVBillUtil.query_counterparty_stats(df_all, names)

        md_msg += f'\n\n## è·Ÿ {names_str} çš„äº¤æ˜“æƒ…å†µ:\n> åŒ…å«çš„åˆ«å:{"|".join(names)}\n\n'
        exclude_keys = {'è¯¦ç»†è®°å½•', 'æœˆåº¦ç»Ÿè®¡', 'å¹´åº¦ç»Ÿè®¡'}
        # print({k: v for k, v in dict_special.items() if k not in exclude_keys})
        display_dict = {k: v for k, v in dict_special.items() if k not in exclude_keys}  # æ ¼å¼åŒ–è¾“å‡ºå­—å…¸
        # md_msg += f'{json.dumps(display_dict, ensure_ascii=False, indent=2, default=str)}'

        md_msg += "| å­—æ®µ | å€¼ |\n"
        md_msg += "|----|----|\n"
        for k, v in display_dict.items():
            if isinstance(v, float):
                v = '{:.0f}'.format(v)
            md_msg += f"| {k} | {v} |\n"
            # md_msg += f' - {k: <4}:\t{v}\n'

        md_msg += f'\n\n### æŒ‰å¹´åº¦ç»Ÿè®¡ç»“æœ:\n{dict_special["å¹´åº¦ç»Ÿè®¡"].to_markdown()}'
        # print(f'\næŒ‰æœˆç»Ÿè®¡ç»“æœ:\n{dict_special["æœˆåº¦ç»Ÿè®¡"].to_string()}')
        # print(f'\næŒ‰å¹´åº¦è®¡ç»“æœ:\n{dict_special["å¹´åº¦ç»Ÿè®¡"].to_string()}')

    print(f'\n\n{md_msg}')
    FileUtil.write2File(md_stats_file, md_msg)
    CommonUtil.printLog(f'ä»¥ä¸Šç»“æœå·²ä¿å­˜åˆ° {md_stats_file}', prefix='\n')


def main2():
    CommonUtil.printLog('å¼€å§‹è½¬æ¢æ‹›å•†é“¶è¡Œè´¦å•PDFä¸ºCSV...')
    target_csv_dir = os.path.dirname(os.path.abspath(__file__))  # å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    pdf_dir = f'{target_csv_dir}/cache/wechat_zfb_bill_lynxz'
    pdf_path = f'{pdf_dir}/æ‹›å•†é“¶è¡Œäº¤æ˜“æµæ°´_20260118.pdf'

    crop_box = (0, 260, 0, -60)
    CSVBillUtil.visualize_crop_area(pdf_path, crop_box=crop_box, save_img_path=f'{pdf_dir}/crop_preview.png')

    csv_path = f'{pdf_path[:-4]}.csv'
    df = CSVBillUtil.cmb_pdf_to_csv(pdf_path, csv_path)
    # CSVUtil.to_csv(df, csv_path)
    # éªŒè¯ï¼šPandasç»Ÿè®¡ç¤ºä¾‹
    if df is not None:
        CommonUtil.printLog("\n=== æµæ°´ç»Ÿè®¡ç»“æœ ===")
        total_income = df[df["Transaction Amount"] > 0]["Transaction Amount"].sum()  # äº¤æ˜“é‡‘é¢
        total_expense = df[df["Transaction Amount"] < 0]["Transaction Amount"].sum()
        CommonUtil.printLog(f"æ€»æ”¶å…¥ï¼š{total_income:.2f} å…ƒ")
        CommonUtil.printLog(f"æ€»æ”¯å‡ºï¼š{total_expense:.2f} å…ƒ")
        CommonUtil.printLog(f"å‡€æ”¶æ”¯ï¼š{total_income + total_expense:.2f} å…ƒ")

        # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
        daily_summary = df.groupby(df["Date"].dt.date)["Transaction Amount"].sum()
        print("\nDaily Transaction Summary:")
        print(daily_summary)
    else:
        CommonUtil.printLog("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æµæ°´æ•°æ®")


if __name__ == '__main__':
    main()
    # main2()
