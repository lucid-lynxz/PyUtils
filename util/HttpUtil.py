# !/usr/bin/env python3
# -*- coding:utf-8 -*-

import os
import traceback
import fnmatch  # ç”¨äºè·¯å¾„é€šé…ç¬¦åŒ¹é…

import requests
from bs4 import BeautifulSoup  # éœ€è¦å®‰è£…: pip install beautifulsoup4


class HTTPUtil(object):
    """
    é€šè¿‡HTTPåè®®ä¸‹è½½Nginxæ˜ å°„çš„ç›®å½•å†…å®¹
    ä¾èµ–: requests, beautifulsoup4
    å®‰è£…ä¾èµ–: pip install requests beautifulsoup4
    """

    def __init__(self, base_url: str, timeout: int = 10):
        self.base_url = base_url.rstrip('/') + '/'  # ç¡®ä¿URLä»¥/ç»“å°¾
        self.timeout = timeout
        self.session = requests.Session()
        # å¯ä»¥æ·»åŠ headersæ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })

    def _parse_directory_index(self, url: str) -> tuple[list[str], list[str]]:
        """è§£æç›®å½•ç´¢å¼•é¡µé¢ï¼Œè¿”å›(æ–‡ä»¶åˆ—è¡¨, å­ç›®å½•åˆ—è¡¨)"""
        try:
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯çŠ¶æ€

            soup = BeautifulSoup(response.text, 'html.parser')
            links = soup.find_all('a')  # è·å–æ‰€æœ‰é“¾æ¥

            files = []
            dirs = []

            for link in links:
                href = link.get('href', '').strip()
                if not href or href.startswith(('?', '#', '/')):  # è¿‡æ»¤æ— æ•ˆé“¾æ¥å’Œç»å¯¹è·¯å¾„
                    continue

                # Nginxé€šå¸¸ä¼šåœ¨ç›®å½•é“¾æ¥ååŠ /ï¼Œæ–‡ä»¶é“¾æ¥åˆ™ä¸ä¼š
                if href.endswith('/'):
                    dirs.append(href.rstrip('/'))
                else:
                    files.append(href)

            return files, dirs

        except Exception as e:
            raise RuntimeError(f"è§£æç›®å½•å¤±è´¥ {url}: {str(e)}")

    def _download_file(self, remote_url: str, local_path: str):
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(local_path), exist_ok=True)

            with self.session.get(remote_url, stream=True, timeout=self.timeout) as response:
                response.raise_for_status()
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0

                with open(local_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            self.progress_callback(downloaded_size, total_size)
            print(f"\nâœ… ä¸‹è½½å®Œæˆ: {local_path}")

        except Exception as e:
            raise RuntimeError(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥ {remote_url}: {str(e)}")

    @staticmethod
    def progress_callback(transferred: int, total: int):
        """ä¼ è¾“è¿›åº¦å›è°ƒå‡½æ•°"""
        if total == 0:
            return
        progress = (transferred / total) * 100
        print(f"\rä¸‹è½½è¿›åº¦: {transferred}/{total} bytes ({progress:.2f}%)", end="")

    def download_directory(self, remote_dir: str = '', local_dir: str = '.', path_pattern: str = None) -> bool:
        """
        ä¸‹è½½è¿œç¨‹ç›®å½•åˆ°æœ¬åœ°
        :param remote_dir: è¿œç¨‹ç›®å½•è·¯å¾„(ç›¸å¯¹äºbase_url)
        :param local_dir: æœ¬åœ°ä¿å­˜ç›®å½•
        :param path_pattern: æ–‡ä»¶è·¯å¾„åŒ¹é…æ¨¡å¼(å¦‚'*/demolog/*.txt')ï¼Œä½¿ç”¨Unixé£æ ¼é€šé…ç¬¦ï¼Œä¸ºNoneæ—¶ä¸‹è½½æ‰€æœ‰æ–‡ä»¶
        """
        try:
            current_url = f"{self.base_url}{remote_dir.lstrip('/')}"
            if not current_url.endswith('/'):
                current_url += '/'

            print(f"æ­£åœ¨è§£æç›®å½•: {current_url}")
            files, dirs = self._parse_directory_index(current_url)

            # ä¸‹è½½å½“å‰ç›®å½•æ–‡ä»¶ï¼ˆæ·»åŠ è·¯å¾„è¿‡æ»¤ï¼‰
            for file in files:
                # æ„å»ºç›¸å¯¹è·¯å¾„å¹¶æ ‡å‡†åŒ–åˆ†éš”ç¬¦ä¸º'/'ï¼ˆç»Ÿä¸€URLé£æ ¼ï¼‰
                relative_file_path = os.path.join(remote_dir, file).replace(os.sep, '/')

                # è·¯å¾„æ¨¡å¼è¿‡æ»¤ï¼ˆå¦‚åŒ¹é…ä»»æ„å±‚çº§demologç›®å½•ä¸‹çš„txtæ–‡ä»¶ï¼‰
                if path_pattern and not fnmatch.fnmatch(relative_file_path, path_pattern):
                    continue

                file_url = f"{current_url}{file}"
                local_path = os.path.join(local_dir, remote_dir, file)
                print(f"\nå¼€å§‹ä¸‹è½½: {file_url}")
                self._download_file(file_url, local_path)

            # é€’å½’ä¸‹è½½å­ç›®å½•ï¼ˆä¼ é€’è·¯å¾„è¿‡æ»¤å‚æ•°ï¼‰
            for dir_name in dirs:
                sub_remote_dir = f"{remote_dir}/{dir_name}".lstrip('/')
                self.download_directory(sub_remote_dir, local_dir, path_pattern)  # ä¼ é€’path_patternå‚æ•°

            print(f"ğŸ“‚ ç›®å½•ä¸‹è½½å®Œæˆ: {os.path.join(local_dir, remote_dir)}")
            return True

        except Exception as e:
            print(f"âŒ ç›®å½•ä¸‹è½½å¤±è´¥: {str(e)}")
            traceback.print_exc()
            return False

    def close(self):
        """å…³é—­ä¼šè¯"""
        self.session.close()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


if __name__ == "__main__":
    # HTTPä¸‹è½½ç¤ºä¾‹
    HTTP_BASE_URL = "http://example.com/nginx-mapped-directory/"  # æ›¿æ¢ä¸ºå®é™…çš„ç›®å½•URL
    LOCAL_SAVE_DIR = "D:/http_downloads"  # æœ¬åœ°ä¿å­˜è·¯å¾„

    with HTTPUtil(base_url=HTTP_BASE_URL) as http:
        # ä¸‹è½½ä»»æ„å±‚çº§ä¸‹demologç›®å½•ä¸­çš„æ‰€æœ‰txtæ–‡ä»¶
        # */demolog/*.txt è¡¨ç¤º: ä»»æ„ç›®å½•/ demologç›®å½•/ ä»»æ„åç§°.txt
        http.download_directory(local_dir=LOCAL_SAVE_DIR, path_pattern="*/demolog/*.txt")